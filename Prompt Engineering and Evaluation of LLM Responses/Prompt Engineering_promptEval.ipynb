{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bde13c-3771-4adf-a18f-2afa7b90a0cc",
   "metadata": {},
   "source": [
    "# Prompt Engineering and Evaluation Of LLM responses\n",
    "\n",
    "- This Notebook is created to evaluate the 100 Prompts created for Prompt Engineering and Evaluation of LLM responses.\n",
    "\n",
    "#### Table of Contents\n",
    "1. [Importing Libraries](#section1)\n",
    "2. [Evaluation of Prompt](#section2)\n",
    "    4.1. Response Length         \n",
    "    4.2. Word Count        \n",
    "    4.3. Sentiment Polarity            \n",
    "    4.4. Sentiment Subjectivity          \n",
    "    4.5. Relevance Score         \n",
    "    4.6. Lexical Diversity                             \n",
    "    4.7. Grammer Errors                    \n",
    "    4.8. Grammer Score                    \n",
    "    4.9. Clarity score                \n",
    "    4.10. Coherence Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14d33e-803e-497e-a447-949fc25bd603",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decb0071-0573-4da6-8fb6-c239a3403624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"prompt_engineering.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c41ea-c8d6-467f-8ab9-ead5f453a6a8",
   "metadata": {},
   "source": [
    "### 2. Evaluation of Prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e52c80a-ac0d-4a07-8750-da5289562841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  \n",
       "0                  7  \n",
       "1                  7  \n",
       "2                  9  \n",
       "3                  9  \n",
       "4                  9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt lenght and word count\n",
    "df['Prompt_length'] = df['Prompt'].str.len()\n",
    "df['Prompt_Word_count'] = df['Prompt'].apply(lambda x: len(x.split())) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5180360-0cbd-4f6e-a555-e1003680a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \n",
       "0                  7         0.000000             0.000000  \n",
       "1                  7         0.000000             0.000000  \n",
       "2                  9         0.000000             0.000000  \n",
       "3                  9         0.166667             0.333333  \n",
       "4                  9         0.200000             0.200000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tone and subjectivity\n",
    "from textblob import TextBlob\n",
    "\n",
    "df['Prompt_Polarity'] = df['Prompt'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['Prompt_subjectivity'] = df['Prompt'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8346b600-1670-466b-9e57-855ba0c1197d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "      <th>Prompt_Lexical_Diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \\\n",
       "0                  7         0.000000             0.000000   \n",
       "1                  7         0.000000             0.000000   \n",
       "2                  9         0.000000             0.000000   \n",
       "3                  9         0.166667             0.333333   \n",
       "4                  9         0.200000             0.200000   \n",
       "\n",
       "   Prompt_Lexical_Diversity  \n",
       "0                  1.000000  \n",
       "1                  1.000000  \n",
       "2                  0.888889  \n",
       "3                  0.888889  \n",
       "4                  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexical Diversity\n",
    "df[\"Prompt_Lexical_Diversity\"] = df[\"Prompt\"].apply(lambda x: len(set(x.split())) / len(x.split()) if len(x.split()) > 0 else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df27200-64da-4d58-be9d-e01d8e74d077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "      <th>Prompt_Lexical_Diversity</th>\n",
       "      <th>Prompt_Grammar_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \\\n",
       "0                  7         0.000000             0.000000   \n",
       "1                  7         0.000000             0.000000   \n",
       "2                  9         0.000000             0.000000   \n",
       "3                  9         0.166667             0.333333   \n",
       "4                  9         0.200000             0.200000   \n",
       "\n",
       "   Prompt_Lexical_Diversity  Prompt_Grammar_errors  \n",
       "0                  1.000000                      0  \n",
       "1                  1.000000                      0  \n",
       "2                  0.888889                      0  \n",
       "3                  0.888889                      0  \n",
       "4                  1.000000                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grammer errors in prompt\n",
    "import language_tool_python\n",
    "\n",
    "tool = language_tool_python.LanguageTool('en-GB')\n",
    "\n",
    "def Grammar_error(text):\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "df['Prompt_Grammar_errors'] = df['Prompt'].apply(Grammar_error)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac73d8d8-6516-4296-aacd-85dcc0c0fbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "      <th>Prompt_Lexical_Diversity</th>\n",
       "      <th>Prompt_Grammar_errors</th>\n",
       "      <th>Prompt_Grammar_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \\\n",
       "0                  7         0.000000             0.000000   \n",
       "1                  7         0.000000             0.000000   \n",
       "2                  9         0.000000             0.000000   \n",
       "3                  9         0.166667             0.333333   \n",
       "4                  9         0.200000             0.200000   \n",
       "\n",
       "   Prompt_Lexical_Diversity  Prompt_Grammar_errors  Prompt_Grammar_score  \n",
       "0                  1.000000                      0                 100.0  \n",
       "1                  1.000000                      0                 100.0  \n",
       "2                  0.888889                      0                 100.0  \n",
       "3                  0.888889                      0                 100.0  \n",
       "4                  1.000000                      0                 100.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grammar_score(text):\n",
    "    #tool = language_tool_python.LanguageTool('en-GB')\n",
    "    matches = tool.check(text)\n",
    "    error_count = len(matches)\n",
    "    word_count = len(text.split())\n",
    "    score = (1 - error_count / word_count) * 100 if word_count > 0 else 0.0\n",
    "    return  round(score, 3)\n",
    "\n",
    "df['Prompt_Grammar_score'] = df['Prompt'].apply(grammar_score)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b620f885-f2c4-4bd8-9d9b-db0372707383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "      <th>Prompt_Lexical_Diversity</th>\n",
       "      <th>Prompt_Grammar_errors</th>\n",
       "      <th>Prompt_Grammar_score</th>\n",
       "      <th>Prompt_Clarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \\\n",
       "0                  7         0.000000             0.000000   \n",
       "1                  7         0.000000             0.000000   \n",
       "2                  9         0.000000             0.000000   \n",
       "3                  9         0.166667             0.333333   \n",
       "4                  9         0.200000             0.200000   \n",
       "\n",
       "   Prompt_Lexical_Diversity  Prompt_Grammar_errors  Prompt_Grammar_score  \\\n",
       "0                  1.000000                      0                 100.0   \n",
       "1                  1.000000                      0                 100.0   \n",
       "2                  0.888889                      0                 100.0   \n",
       "3                  0.888889                      0                 100.0   \n",
       "4                  1.000000                      0                 100.0   \n",
       "\n",
       "   Prompt_Clarity_score  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clarity \n",
    "def get_clarity(text):\n",
    "    matches = tool.check(text)\n",
    "    error_ratio = len(matches) / max(len(text.split()), 1)\n",
    "    return error_ratio\n",
    "\n",
    "df[\"Prompt_Clarity_score\"] = df['Prompt'].apply(get_clarity)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de1be59-c84f-4a26-9b1a-8ec6ef52eb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Krishnapriya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\Krishnapriya\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "      <th>Prompt_Lexical_Diversity</th>\n",
       "      <th>Prompt_Grammar_errors</th>\n",
       "      <th>Prompt_Grammar_score</th>\n",
       "      <th>Prompt_Clarity_score</th>\n",
       "      <th>Prompt_Coherence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \\\n",
       "0                  7         0.000000             0.000000   \n",
       "1                  7         0.000000             0.000000   \n",
       "2                  9         0.000000             0.000000   \n",
       "3                  9         0.166667             0.333333   \n",
       "4                  9         0.200000             0.200000   \n",
       "\n",
       "   Prompt_Lexical_Diversity  Prompt_Grammar_errors  Prompt_Grammar_score  \\\n",
       "0                  1.000000                      0                 100.0   \n",
       "1                  1.000000                      0                 100.0   \n",
       "2                  0.888889                      0                 100.0   \n",
       "3                  0.888889                      0                 100.0   \n",
       "4                  1.000000                      0                 100.0   \n",
       "\n",
       "   Prompt_Clarity_score  Prompt_Coherence_score  \n",
       "0                   0.0                0.159370  \n",
       "1                   0.0                0.187638  \n",
       "2                   0.0                0.243827  \n",
       "3                   0.0                0.206220  \n",
       "4                   0.0                0.485444  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_coherence(text):\n",
    "    \"\"\"\n",
    "    Calculate coherence for both multi-sentence and single-sentence texts.\n",
    "    For single sentences: checks coherence between halves of the sentence.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Multi-sentence case\n",
    "    if len(sentences) >= 2:\n",
    "        embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "        sims = [util.pytorch_cos_sim(embeddings[i], embeddings[i+1]).item() \n",
    "               for i in range(len(sentences)-1)]\n",
    "        return sum(sims) / len(sims)\n",
    "    \n",
    "    # Single-sentence case: split sentence into two parts\n",
    "    else:\n",
    "        words = text.split()\n",
    "        if len(words) < 2:\n",
    "            return 1.0  # trivial case: single word is perfectly coherent with itself\n",
    "        \n",
    "        half = len(words) // 2\n",
    "        parts = [\n",
    "            ' '.join(words[:half]),\n",
    "            ' '.join(words[half:])\n",
    "        ]\n",
    "        embeddings = model.encode(parts, convert_to_tensor=True)\n",
    "        return util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()\n",
    "\n",
    "df[\"Prompt_Coherence_score\"] = df['Prompt'].apply(get_coherence)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324ff5cf-d5bc-4ef1-ab46-1094331d550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "      <th>Prompt_Lexical_Diversity</th>\n",
       "      <th>Prompt_Grammar_errors</th>\n",
       "      <th>Prompt_Grammar_score</th>\n",
       "      <th>Prompt_Clarity_score</th>\n",
       "      <th>Prompt_Coherence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \\\n",
       "0                  7         0.000000             0.000000   \n",
       "1                  7         0.000000             0.000000   \n",
       "2                  9         0.000000             0.000000   \n",
       "3                  9         0.166667             0.333333   \n",
       "4                  9         0.200000             0.200000   \n",
       "\n",
       "   Prompt_Lexical_Diversity  Prompt_Grammar_errors  Prompt_Grammar_score  \\\n",
       "0                  1.000000                      0                 100.0   \n",
       "1                  1.000000                      0                 100.0   \n",
       "2                  0.888889                      0                 100.0   \n",
       "3                  0.888889                      0                 100.0   \n",
       "4                  1.000000                      0                 100.0   \n",
       "\n",
       "   Prompt_Clarity_score  Prompt_Coherence_score  \n",
       "0                   0.0                0.159370  \n",
       "1                   0.0                0.187638  \n",
       "2                   0.0                0.243827  \n",
       "3                   0.0                0.206220  \n",
       "4                   0.0                0.485444  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace('N/A', 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee57a6fc-49c1-4979-ab10-7ec6e4cd67e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Prompt_length</th>\n",
       "      <th>Prompt_Word_count</th>\n",
       "      <th>Prompt_Polarity</th>\n",
       "      <th>Prompt_subjectivity</th>\n",
       "      <th>Prompt_Lexical_Diversity</th>\n",
       "      <th>Prompt_Grammar_errors</th>\n",
       "      <th>Prompt_Grammar_score</th>\n",
       "      <th>Prompt_Clarity_score</th>\n",
       "      <th>Prompt_Coherence_score</th>\n",
       "      <th>Sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What is the tallest mountain in Africa?</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159370</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factual</td>\n",
       "      <td>List three differences between viruses and bac...</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187638</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Describe the causes and effects of the French ...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243827</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Factual</td>\n",
       "      <td>What are the main responsibilities of the Unit...</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206220</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factual</td>\n",
       "      <td>Explain the economic consequences of inflation...</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485444</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                             Prompt  Prompt_length  \\\n",
       "0  Factual            What is the tallest mountain in Africa?             39   \n",
       "1  Factual  List three differences between viruses and bac...             52   \n",
       "2  Factual  Describe the causes and effects of the French ...             57   \n",
       "3  Factual  What are the main responsibilities of the Unit...             57   \n",
       "4  Factual  Explain the economic consequences of inflation...             71   \n",
       "\n",
       "   Prompt_Word_count  Prompt_Polarity  Prompt_subjectivity  \\\n",
       "0                  7            0.000             0.000000   \n",
       "1                  7            0.000             0.000000   \n",
       "2                  9            0.000             0.000000   \n",
       "3                  9            0.167             0.333333   \n",
       "4                  9            0.200             0.200000   \n",
       "\n",
       "   Prompt_Lexical_Diversity  Prompt_Grammar_errors  Prompt_Grammar_score  \\\n",
       "0                     1.000                      0                 100.0   \n",
       "1                     1.000                      0                 100.0   \n",
       "2                     0.889                      0                 100.0   \n",
       "3                     0.889                      0                 100.0   \n",
       "4                     1.000                      0                 100.0   \n",
       "\n",
       "   Prompt_Clarity_score  Prompt_Coherence_score  Sentiment_subjectivity  \n",
       "0                   0.0                0.159370                   0.000  \n",
       "1                   0.0                0.187638                   0.000  \n",
       "2                   0.0                0.243827                   0.000  \n",
       "3                   0.0                0.206220                   0.333  \n",
       "4                   0.0                0.485444                   0.200  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rounding of the evalution metrics to 3 places\n",
    "df['Prompt_Polarity'] = df['Prompt_Polarity'].apply(lambda x: round(x, 3))\n",
    "df['Sentiment_subjectivity'] = df['Prompt_subjectivity'].apply(lambda x: round(x,3))\n",
    "df['Prompt_Lexical_Diversity'] = df['Prompt_Lexical_Diversity'].apply(lambda x: round(x,3))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a691f0a3-9c4d-4324-b388-81ba5d948137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Prompt_Evalmetrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2a267-cceb-419f-a81d-fe16c4bf589c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
