# Multi-Dimensional Evaluation and Application of Generative AI: A Study of Prompt Effectiveness, Ethical Risks, and Real-World Use Case

This repository contains a collection of experiments and implementations around **Generative AI Models**.        
**1. Prompt Engineering and Evaluation of LLMs**                    
**2. Bias & Toxicity Detection**            
**3. Text-to-Image Generation**              

The project explores different aspects of **Generative AI** using **Gemini API, GPT models, Stable Diffusion, and Traditional NLP methods**, alongside various **evaluation metrics and visualizations** for the academic purpose. 

##### Motivation for the project: 
One of the most perplexing challenges I encountered while studying LLMs was understanding how computers interpret bias, a complex and crucial factor that influences AI‚Äôs ability to mimic human thinking. Given that prompt-generated responses are central to how AI expresses reasoning, I became particularly interested in evaluating the biased outputs produced by different Generative AI models in response to various prompts.

###### Note: A combined code script is named: Multi-Dimensional_Prompt_Evaluation.ipynb
---

## üìë Table of Contents  
1. [Prompt Engineering and Evaluation of LLM Response](#a-prompt-engineering-and-evaluation-of-llm-response)   
2. [Bias & Toxicity Detection](#c-bias-and-toxicity-detection-in-the-text-using-llm)  
3. [Text-to-Image Generation & Relevance Evaluation](#d-text-to-image-generation-using-llm--relevance-evaluation)  
4. [Tools and Technologies Used](#technologies-used)  

---

## 1. Prompt Engineering and Evaluation of LLM Response  

- **Dataset**: 100 prompts across 10 categories: *Factual, Creative Writing, Instructional, Philosophical, Casual, Analytical, Professional, Personal Growth, Technical, Open-ended*.  
- Prompts were applied to the **Gemini model**, and the resulting responses were evaluated.

### üìù Evaluation Metrics  
- Response Length & Word Count  
- Sentiment Polarity(Tone) & Subjectivity  
- Lexical Diversity  
- Grammar Errors & Grammar Score
- Clarity and Coherence
- Prompt and response relevance

### üìä Visualizations  
- Prompt and Response length by category  
- Prompt and Response Polarity & Subjectivity by category  
- Prompt and response Lexical diversity by category  
- Grammar Score and Grammatical error for prompt and Responses
- Clarity and Coherence plots for Prompt and Responses by category
- Correlation heatmap between numerical variables(Evaluated scores)
- Prompt and Response relevance score by category

### Results
 - Created an automated pipeline for evaluation
 - The evaluation shows that LLM responses are generally grammatically strong (92‚Äì100%) and predominantly positive across categories.
 - Instructional, factual, and professional prompts yield the most relevant and accurate results, while casual and creative prompts show greater subjectivity, variability, and occasional negativity.
 - Overall, Gemini API performs reliably, with response quality varying based on prompt type.

### Folder Structure
**Folder**: Prompt Engineering and Evaluation of LLM Response                                          
**Subfolders**: 
- *Prompt_engineering.ipynb*: This is the main python file. It contains responses generated by Gemini API, Visualisations and insights for the responses generated.
- *prompt_engineering.csv*: File contains 100 prompts used for prompt engineering.
- *PE_Evalmetrics.csv*: File contains Evaluated metrics of responses generated by Gemini API for Prompt Engineering.
- *PE_Responses.csv*: File contains responses generated by Gemini API for Prompt Engineering.
- *Prompt Engineering_promptEval.ipynb*: File contains evaluation metrics for 100 prompts created for Prompt Engineeing.
- *Prompt_Evalmetrics.csv*: File contains evaluated metrics of prompts created for Prompt Engineeing.

---

## 2. Bias and Toxicity Detection in the Text using LLM  

### 2.1 Bias Detection  
- **100 biased prompts** across specific categories: Gender, Religion, Ethnicity, Socioeconomic, Sexual Orientation, Neutral  
- Used Gemini API to classify type of Bias in above specified categories.
- **Evaluation Metrics:** Classification Report + Confusion Matrix

#### Results
- The model excels in detecting Sexual Orientation and Socioeconomic bias with perfect scores (F1 = 1.0) and performs strongly on Gender and Ethnicity biases (F1 ‚âà 0.9 and 0.8).
- However, it struggles with Neutral (low precision, many false positives) and Religion (low recall, many false negatives), making these the weakest categories.

### 2.2 Toxicity Detection  
- **Models Used:**  
  - Perspective API  
  - Detoxify  
  - Gemini API (custom toxicity scoring)  

- **Evaluation Metrics:** Toxicity, Severe Toxicity, Insult, Profanity, Threat, Identity Attack, Number of Misclassifications. 
- **Visualizations:**  
  - Confusion matrices & classification reports  
  - Radar chart for overall comparison

#### Results
- Gemini demonstrates the most comprehensive toxicity detection, covering all six categories with strong performance in severe toxicity, identity attacks, and threats.
- Perspective provides moderate coverage in detecting toxicity.
-  Detoxify is relatively strong in profanity but underperforms in threat and severe toxicity.
-  Overall, Gemini is best suited for broad detection, while tool choice depends on the specific focus of toxicity monitoring.

### Folder Structure
**Folder**: Bias and Toxicity detection in text                                           
**Subfolders**:   
- *Bias_Toxicity_detection.ipynb*: This is the main Python Code file. It contains the responses generated by models for Bias and Toxicity, their evaluations, visualisations and insights.
- *Bias_prompts.csv*: File contains 100 prompts with different Bias prompts.
- *Bias_responses.csv*: File contains the responses Generated by Gemini API for respective prompts.
- *Toxicity_prompt.csv*: File contains 100 prompts with different Toxicity prompts.
- *Toxicity score using Gemini API.ipynb*: This Python file is used generate toxicity sores for gemini API generated responses.
- *Toxic_response_d.csv*: File contains toxicity responses generated by detoxify.
- *Toxic_response_g.csv*: File contains toxicity responses generated by Gemini API.
- *Toxicity_response_p.csv*: File contains toxicity responses generated by Perspective API.
- *Toxicity_scores_gemini*: Files contains the toxicity scores generated by Gemini API. 

---

## 3. Text-to-Image Generation using LLM & Relevance Evaluation  
- **Dataset**: 100 Prompts across 5 categories: *Nature, Cityscapes & structures, People, Commercial Products, Artistic*.
  - Prompts were applied to Gemini Model as well as Stable Diffusion and further evaluated by Metrics as well as humans.

- **Models Used**:
    - Gemini API: gemini-2.0-flash-preview-image-generation
    - Stable Diffusion: stable-diffusion-v1-5

- **Evaluation:**
    - Clip Score
    - Blip Score
    - Inception Score
    - Human Evaluation

#### Result:
Both Gemini and Stable Diffusion are powerful image generation models that excel at producing high-quality, realistic images. However, based on the Evaluation metrics, Gemini appears to be better at generating images that are more easily understood and described by a language model. This could make Gemini a more predictable choice for applications that require a strong, clear, and literal interpretation of the text prompt. 

### Folder Structure
**Folder**: Bias and Toxicity detection in text                                           
**Subfolders**:     
- *Text _to_image_generation_modified.ipynb*: This the main Python code file for image generation using gemini and evalution of scores for both gemini as well as Stable diffusion.
- *Stable_diffusion_generation.ipynb*: File contains code for image generation using stable diffusion.
- *Image_Evalmetrics.csv*: File contains the evaluated metrics for generated images using both models.
- *inception_score_per_category.csv*: File contains inceptions scores per image category generated for Gemini generated images.
- *inception_score_per_category_SD.csv*: File contains inceptions scores per image category generated for Stable Diffusion generated images.

---

## 4. Tools and Technologies Used  

- **LLMs & APIs:** Gemini API, HuggingFace Transformers(BERT, BART), Stable Diffusion, Detoxify, Perspective API
- **Traditional NLP:** Scikit-learn, Sumy, NLTK, PDF2Image
- **Visualization:** Matplotlib, Seaborn, Radar charts, Pairplots, Heatmaps, Barplots & Grouped Bar plots, Confusion Matrix, Plotly   
- **Deployment:** Streamlit Cloud

---
**Note: Incase of further clarification, please contact: kskp2512@gmail.com**
